{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c0ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "device = \"cpu\"\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('../data/mtsamples_cleaned.csv')\n",
    "\n",
    "# Convert string representation of list back to actual list\n",
    "df['filtered_keywords'] = df['filtered_keywords'].apply(ast.literal_eval)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['filtered_keywords'])\n",
    "\n",
    "with open('../models/mlb_classes.pkl', 'rb') as f:\n",
    "    classes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class PMSIDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, targets):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.transcription\n",
    "        self.targets = targets\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text.iloc[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_len,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(inputs['token_type_ids'], dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49523b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "train_df, val_df, train_targets, val_targets = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "training_set = PMSIDataset(train_df, tokenizer, MAX_LEN, train_targets)\n",
    "validation_set = PMSIDataset(val_df, tokenizer, MAX_LEN, val_targets)\n",
    "\n",
    "training_loader = DataLoader(training_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=VALID_BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa71b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class PMSIModel(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(PMSIModel, self).__init__()\n",
    "        self.bert = transformers.AutoModel.from_pretrained(MODEL_NAME)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(768, n_classes)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)\n",
    "\n",
    "model = PMSIModel(len(classes))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function (Weighted for Imbalance)\n",
    "class_counts = y.sum(axis=0)\n",
    "total_samples = len(y)\n",
    "pos_weights = (total_samples - class_counts) / (class_counts + 1e-5)\n",
    "pos_weights_tensor = torch.tensor(pos_weights, dtype=torch.float).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_model(epoch):\n",
    "    model.train()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device)\n",
    "        mask = data['mask'].to(device)\n",
    "        token_type_ids = data['token_type_ids'].to(device)\n",
    "        targets = data['targets'].to(device)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print(f'Step {i}, Loss: {loss.item():.4f}')\n",
    "            \n",
    "    print(f\"Epoch {epoch+1} Complete. Avg Loss: {total_loss / len(training_loader):.4f}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_model(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "torch.save(model.state_dict(), '../models/pmsi_model_conf.bin')\n",
    "print(\"Model saved to ../models/pmsi_model_conf.bin\")                            "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
